{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "_5Jizb09zmTw",
    "outputId": "8bbb7850-d2d7-4256-8183-bbacd62374eb",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:00.302438Z",
     "start_time": "2025-12-03T16:43:59.699699Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "\n",
    "# Detect environment (Colab vs Local)\n",
    "running_in_colab = \"COLAB_GPU\" in os.environ\n",
    "\n",
    "if running_in_colab:\n",
    "    BASE = Path(\"/content/data\")\n",
    "    if not BASE.exists():\n",
    "        BASE = Path(\"/content\")\n",
    "else:\n",
    "    current_dir = Path.cwd()\n",
    "\n",
    "    # If notebook is inside /notebooks/, data is one level up\n",
    "    if (current_dir.parent / \"data\").exists():\n",
    "        BASE = current_dir.parent / \"data\"\n",
    "    # If notebook and data are in same/root folder\n",
    "    elif (current_dir / \"data\").exists():\n",
    "        BASE = current_dir / \"data\"\n",
    "    else:\n",
    "        BASE = current_dir\n",
    "        print(\"Warning: Could not find 'data' folder. Using current directory.\")\n",
    "\n",
    "print(\"Using BASE directory:\", BASE)\n",
    "\n",
    "# Correct path to processed_data_ready_for_modeling.csv\n",
    "data_path = BASE / \"processed_data_ready_for_modeling.csv\"\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Data loaded. Shape: {df.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Using BASE directory: D:\\fraud_detection_project\\data\n",
      "Data loaded. Shape: (5410, 22)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w-S53Sw_0Dln",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:00.325323Z",
     "start_time": "2025-12-03T16:44:00.307864Z"
    }
   },
   "source": [
    "# Separate features and target\n",
    "X = df.drop(\"PotentialFraud\", axis=1)\n",
    "y = df[\"PotentialFraud\"]\n",
    "\n",
    "print(\"Target value counts:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# First split: train (60%) + temp (40%)\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: validation (20%) + test (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}, class dist:\\n{y_train_full.value_counts()}\")\n",
    "print(f\"Val shape:   {X_val.shape}, class dist:\\n{y_val.value_counts()}\")\n",
    "print(f\"Test shape:  {X_test.shape}, class dist:\\n{y_test.value_counts()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value counts:\n",
      "PotentialFraud\n",
      "0    4904\n",
      "1     506\n",
      "Name: count, dtype: int64\n",
      "Train shape: (3246, 21), class dist:\n",
      "PotentialFraud\n",
      "0    2942\n",
      "1     304\n",
      "Name: count, dtype: int64\n",
      "Val shape:   (1082, 21), class dist:\n",
      "PotentialFraud\n",
      "0    981\n",
      "1    101\n",
      "Name: count, dtype: int64\n",
      "Test shape:  (1082, 21), class dist:\n",
      "PotentialFraud\n",
      "0    981\n",
      "1    101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LIfXTSOw0Ii2",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:03.271822Z",
     "start_time": "2025-12-03T16:44:00.598013Z"
    }
   },
   "source": [
    "# Scale features (needed for Logistic Regression, helpful for GB)\n",
    "scaler = StandardScaler()\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to keep column names if needed\n",
    "X_train_full_scaled = pd.DataFrame(X_train_full_scaled, columns=X.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Features scaled.\")\n",
    "\n",
    "# Initialize SMOTE and apply ONLY on training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_full_scaled, y_train_full)\n",
    "\n",
    "print(\"\\nTraining class distribution before SMOTE:\")\n",
    "print(y_train_full.value_counts())\n",
    "print(\"\\nTraining class distribution after SMOTE:\")\n",
    "print(y_train_smote.value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled.\n",
      "\n",
      "Training class distribution before SMOTE:\n",
      "PotentialFraud\n",
      "0    2942\n",
      "1     304\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training class distribution after SMOTE:\n",
      "PotentialFraud\n",
      "0    2942\n",
      "1    2942\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "86LlPrIa0Lkk",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:03.350751Z",
     "start_time": "2025-12-03T16:44:03.341749Z"
    }
   },
   "source": [
    "def evaluate_model(name, model, X_tr, y_tr, X_v, y_v):\n",
    "    \"\"\"\n",
    "    Fit model on training data and evaluate on validation data.\n",
    "    Returns metrics dict plus predictions and probabilities.\n",
    "    \"\"\"\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = model.predict(X_v)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_v)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_v)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"precision\": precision_score(y_v, y_pred),\n",
    "        \"recall\": recall_score(y_v, y_pred),\n",
    "        \"f1\": f1_score(y_v, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_v, y_proba),\n",
    "        \"pr_auc\": average_precision_score(y_v, y_proba)\n",
    "    }\n",
    "    return metrics, y_pred, y_proba\n",
    "\n",
    "print(\"Evaluation helper ready.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation helper ready.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "H0YdI1OF0OwJ",
    "outputId": "77d23e0f-2409-4cce-cfab-2c1bdaafcac3",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:06.558694Z",
     "start_time": "2025-12-03T16:44:03.418814Z"
    }
   },
   "source": [
    "results = {}\n",
    "\n",
    "# 1) Random Forest on SMOTE data\n",
    "print(\"Training primary model: Random Forest (SMOTE)...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_results, y_val_pred_rf, y_val_proba_rf = evaluate_model(\n",
    "    \"RF_SMOTE\",\n",
    "    rf_model,\n",
    "    X_train_smote, y_train_smote,\n",
    "    X_val_scaled, y_val\n",
    ")\n",
    "results[\"RF_SMOTE\"] = rf_results\n",
    "print(\"RF_SMOTE results:\", rf_results)\n",
    "\n",
    "# 2) Logistic Regression (SMOTE)\n",
    "print(\"\\nTraining comparison model 1: Logistic Regression (SMOTE)...\")\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "lr_results, y_val_pred_lr, y_val_proba_lr = evaluate_model(\n",
    "    \"LogReg_SMOTE\",\n",
    "    lr_model,\n",
    "    X_train_smote, y_train_smote,\n",
    "    X_val_scaled, y_val\n",
    ")\n",
    "results[\"LogReg_SMOTE\"] = lr_results\n",
    "print(\"LogReg_SMOTE results:\", lr_results)\n",
    "\n",
    "# 3) Gradient Boosting (SMOTE)\n",
    "print(\"\\nTraining comparison model 2: Gradient Boosting (SMOTE)...\")\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "gb_results, y_val_pred_gb, y_val_proba_gb = evaluate_model(\n",
    "    \"GB_SMOTE\",\n",
    "    gb_model,\n",
    "    X_train_smote, y_train_smote,\n",
    "    X_val_scaled, y_val\n",
    ")\n",
    "results[\"GB_SMOTE\"] = gb_results\n",
    "print(\"GB_SMOTE results:\", gb_results)\n",
    "\n",
    "print(\"\\nValidation metrics summary:\")\n",
    "pd.DataFrame(results).T"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training primary model: Random Forest (SMOTE)...\n",
      "RF_SMOTE results: {'model': 'RF_SMOTE', 'precision': 0.6410256410256411, 'recall': 0.7425742574257426, 'f1': 0.6880733944954128, 'roc_auc': 0.9551225764778313, 'pr_auc': 0.7577305178565125}\n",
      "\n",
      "Training comparison model 1: Logistic Regression (SMOTE)...\n",
      "LogReg_SMOTE results: {'model': 'LogReg_SMOTE', 'precision': 0.49710982658959535, 'recall': 0.8514851485148515, 'f1': 0.6277372262773723, 'roc_auc': 0.9577214602194163, 'pr_auc': 0.7905023148150148}\n",
      "\n",
      "Training comparison model 2: Gradient Boosting (SMOTE)...\n",
      "GB_SMOTE results: {'model': 'GB_SMOTE', 'precision': 0.5845070422535211, 'recall': 0.8217821782178217, 'f1': 0.6831275720164609, 'roc_auc': 0.9497229539467709, 'pr_auc': 0.7859825912449433}\n",
      "\n",
      "Validation metrics summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     model precision    recall        f1   roc_auc    pr_auc\n",
       "RF_SMOTE          RF_SMOTE  0.641026  0.742574  0.688073  0.955123  0.757731\n",
       "LogReg_SMOTE  LogReg_SMOTE   0.49711  0.851485  0.627737  0.957721  0.790502\n",
       "GB_SMOTE          GB_SMOTE  0.584507  0.821782  0.683128  0.949723  0.785983"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF_SMOTE</th>\n",
       "      <td>RF_SMOTE</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.955123</td>\n",
       "      <td>0.757731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_SMOTE</th>\n",
       "      <td>LogReg_SMOTE</td>\n",
       "      <td>0.49711</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.957721</td>\n",
       "      <td>0.790502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB_SMOTE</th>\n",
       "      <td>GB_SMOTE</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.683128</td>\n",
       "      <td>0.949723</td>\n",
       "      <td>0.785983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JwCnJOhE0Ruu",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:20.275650Z",
     "start_time": "2025-12-03T16:44:06.672749Z"
    }
   },
   "source": [
    "print(\"\\nStarting lightweight RF_SMOTE hyperparameter tuning...\")\n",
    "\n",
    "rf_base_smote = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "grid_smote = GridSearchCV(\n",
    "    rf_base_smote,\n",
    "    param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Tune using SMOTE training data\n",
    "grid_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "best_rf_smote_tuned = grid_smote.best_estimator_\n",
    "print(\"Best params (RF_SMOTE):\", grid_smote.best_params_)\n",
    "\n",
    "rf_smote_tuned_results, y_val_pred_rf_tuned, y_val_proba_rf_tuned = evaluate_model(\n",
    "    \"RF_SMOTE_tuned\",\n",
    "    best_rf_smote_tuned,\n",
    "    X_train_smote, y_train_smote,\n",
    "    X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "print(\"\\nRF_SMOTE_tuned results:\", rf_smote_tuned_results)\n",
    "\n",
    "# Compare RF_SMOTE vs RF_SMOTE_tuned\n",
    "comparison = {\n",
    "    \"RF_SMOTE\": rf_results,\n",
    "    \"RF_SMOTE_tuned\": rf_smote_tuned_results,\n",
    "    \"GB_SMOTE\": gb_results,\n",
    "    \"LogReg_SMOTE\": lr_results\n",
    "}\n",
    "print(\"\\nAll model variants (validation):\")\n",
    "pd.DataFrame(comparison).T"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting lightweight RF_SMOTE hyperparameter tuning...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best params (RF_SMOTE): {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "RF_SMOTE_tuned results: {'model': 'RF_SMOTE_tuned', 'precision': 0.6440677966101694, 'recall': 0.7524752475247525, 'f1': 0.6940639269406392, 'roc_auc': 0.9560662488267175, 'pr_auc': 0.762651509749543}\n",
      "\n",
      "All model variants (validation):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                         model precision    recall        f1   roc_auc  \\\n",
       "RF_SMOTE              RF_SMOTE  0.641026  0.742574  0.688073  0.955123   \n",
       "RF_SMOTE_tuned  RF_SMOTE_tuned  0.644068  0.752475  0.694064  0.956066   \n",
       "GB_SMOTE              GB_SMOTE  0.584507  0.821782  0.683128  0.949723   \n",
       "LogReg_SMOTE      LogReg_SMOTE   0.49711  0.851485  0.627737  0.957721   \n",
       "\n",
       "                  pr_auc  \n",
       "RF_SMOTE        0.757731  \n",
       "RF_SMOTE_tuned  0.762652  \n",
       "GB_SMOTE        0.785983  \n",
       "LogReg_SMOTE    0.790502  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF_SMOTE</th>\n",
       "      <td>RF_SMOTE</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.955123</td>\n",
       "      <td>0.757731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_SMOTE_tuned</th>\n",
       "      <td>RF_SMOTE_tuned</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.694064</td>\n",
       "      <td>0.956066</td>\n",
       "      <td>0.762652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB_SMOTE</th>\n",
       "      <td>GB_SMOTE</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.683128</td>\n",
       "      <td>0.949723</td>\n",
       "      <td>0.785983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_SMOTE</th>\n",
       "      <td>LogReg_SMOTE</td>\n",
       "      <td>0.49711</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.957721</td>\n",
       "      <td>0.790502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qjmxkrYqmaqy",
    "ExecuteTime": {
     "end_time": "2025-12-03T16:44:21.438812Z",
     "start_time": "2025-12-03T16:44:20.318281Z"
    }
   },
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Decide best model (here we assume RF_SMOTE_tuned is best; adjust if needed)\n",
    "final_model = best_rf_smote_tuned\n",
    "final_model_name = \"RF_SMOTE_tuned\"\n",
    "\n",
    "print(f\"Final chosen model: {final_model_name}\")\n",
    "\n",
    "# Retrain final model on FULL train (train_full + val) with SMOTE again\n",
    "X_train_full_all = pd.concat([X_train_full_scaled, X_val_scaled], axis=0)\n",
    "y_train_full_all = pd.concat([y_train_full, y_val], axis=0)\n",
    "\n",
    "X_train_full_smote, y_train_full_smote = smote.fit_resample(X_train_full_all, y_train_full_all)\n",
    "print(\"Full train after SMOTE:\", y_train_full_smote.value_counts())\n",
    "\n",
    "final_model.fit(X_train_full_smote, y_train_full_smote)\n",
    "\n",
    "# Evaluate on TEST set (scaled, original distribution)\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "y_test_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "test_metrics = {\n",
    "    \"precision\": precision_score(y_test, y_test_pred),\n",
    "    \"recall\": recall_score(y_test, y_test_pred),\n",
    "    \"f1\": f1_score(y_test, y_test_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "    \"pr_auc\": average_precision_score(y_test, y_test_proba)\n",
    "}\n",
    "\n",
    "print(\"\\nFinal test metrics for\", final_model_name, \":\", test_metrics)\n",
    "\n",
    "# Save all artifacts for Notebook 3\n",
    "artifacts = {\n",
    "    \"rf_model\": rf_model,\n",
    "    \"lr_model\": lr_model,\n",
    "    \"gb_model\": gb_model,\n",
    "    \"best_model\": final_model,\n",
    "    \"X_test\": X_test_scaled,\n",
    "    \"y_test\": y_test,\n",
    "    \"scaler\": scaler,\n",
    "    \"feature_names\": X.columns.tolist()\n",
    "}\n",
    "\n",
    "model_filename = BASE / \"trained_models_and_test_data.pkl\"\n",
    "joblib.dump(artifacts, model_filename)\n",
    "\n",
    "print(f\"\\nAll models and test data saved to: {model_filename}\")\n",
    "print(\"Ready for Notebook 03 (Evaluation).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chosen model: RF_SMOTE_tuned\n",
      "Full train after SMOTE: PotentialFraud\n",
      "0    3923\n",
      "1    3923\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final test metrics for RF_SMOTE_tuned : {'precision': 0.5555555555555556, 'recall': 0.7425742574257426, 'f1': 0.635593220338983, 'roc_auc': 0.9431323866331588, 'pr_auc': 0.7103441119079906}\n",
      "\n",
      "All models and test data saved to: D:\\fraud_detection_project\\data\\trained_models_and_test_data.pkl\n",
      "Ready for Notebook 03 (Evaluation).\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
